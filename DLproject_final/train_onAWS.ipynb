{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyEDFlib\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import warnings \n",
    "import os\n",
    "import collections\n",
    "from PIL import Image\n",
    "from numpy.random import seed \n",
    "import tensorflow\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -r -N -c -np https://physionet.org/files/chbmit/1.0.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathDataSet = 'physionet.org/files/chbmit/1.0.0/'  # path of the dataset\n",
    "patients = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\"]   # the record of the patients we use to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSummaryPatient(index): \n",
    "    f = open(pathDataSet+'chb'+patients[index]+'/chb'+patients[index]+'-summary.txt', 'r')\n",
    "    parent = 'chb'+patients[index]+'/'\n",
    "    return f, parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seizureImageGenerate(secSt, secEn, name_F, parent):\n",
    "    file1 = pyedflib.EdfReader(pathDataSet+parent+name_F)\n",
    "    n = file1.signals_in_file\n",
    "    signal_labels = file1.getSignalLabels()\n",
    "    signal_headers = file1.getSignalHeaders()\n",
    "    rate = signal_headers[0]['sample_rate']\n",
    "    dur = file1.getFileDuration()\n",
    "    x = np.zeros((n, file1.getNSamples()[0]))\n",
    "    for i in range(n):\n",
    "        x[i,:] = file1.readSignal(i)\n",
    "        label = file1.getLabel(i)\n",
    "    file1.close()\n",
    "    # a = os.getcwd()\n",
    "    path = 'chbfig/'+ parent\n",
    "    if os.path.isdir(path) is not True:\n",
    "        os.makedirs(path)\n",
    "    picnum = int(dur*rate/256)\n",
    "    for i in range(picnum):\n",
    "        img = x[:,i*256:(i+1)*256]\n",
    "        Img = Image.fromarray(np.uint8(img))\n",
    "        if secSt <= i+1 <= secEn:\n",
    "            filename = '_seizure_'+ str(i)\n",
    "            Img.save(path + name_F.split('.')[0] + filename+'.jpg')\n",
    "        else:\n",
    "            filename = '_nonseizure_'+ str(i)\n",
    "            Img.save(path + name_F.split('.')[0] + filename+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset():\n",
    "    print(\"START \\n\")\n",
    "    for indexPatient in range(0, len(patients)):\n",
    "        # fileList = []\n",
    "    \n",
    "        f, parent = loadSummaryPatient(indexPatient)\n",
    "        line=f.readline()\n",
    "        while (line):\n",
    "            data=line.split(':')\n",
    "            if (data[0]==\"File Name\"):\n",
    "                name_F=data[1].strip()\n",
    "                # print(name_F)\n",
    "                for i in range(3):\n",
    "                    line=f.readline()\n",
    "                for j in range(0, int(line.split(': ')[1])):\n",
    "                    secSt=int(f.readline().split(': ')[1].split(' ')[0])\n",
    "                    secEn=int(f.readline().split(': ')[1].split(' ')[0])\n",
    "                    seizureImageGenerate(secSt, secEn, name_F, parent)\n",
    "\n",
    "            line=f.readline()\n",
    "        f.close()\n",
    "\n",
    "    print(\"END \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testlabelGenerate():\n",
    "    parent_path = 'chbfig/'\n",
    "    featureList = []\n",
    "    labelList = []\n",
    "    for indexPatient in range(0, len(test_patients)):         # len(patients)\n",
    "        sub_path = 'chb'+test_patients[indexPatient]+'/'\n",
    "        print(sub_path)\n",
    "        directory_name = parent_path+sub_path\n",
    "        features = np.zeros((len(os.listdir(directory_name)),23,256))\n",
    "        labels = np.zeros((len(os.listdir(directory_name))),dtype=int)\n",
    "        i = 0 #the feature index\n",
    "        for filename in os.listdir(directory_name):\n",
    "            # print(filename)\n",
    "            if '_seizure_' in filename:\n",
    "                im_features = np.array(Image.open(directory_name+filename))\n",
    "                features[i] = im_features[0:23,:]\n",
    "                labels[i] = 1\n",
    "            elif '_nonseizure_' in filename:\n",
    "                im_features = np.array(Image.open(directory_name+filename))\n",
    "                features[i] = im_features[0:23,:]\n",
    "                labels[i] = 0\n",
    "            i = i+1\n",
    "\n",
    "        featureList.append(features)\n",
    "        labelList.append(labels)\n",
    "\n",
    "    X = featureList[0]\n",
    "    Y = labelList[0]\n",
    "    for j in range(1,len(featureList)):\n",
    "        X = np.vstack((X,featureList[j]))\n",
    "        Y = np.hstack((Y,labelList[j]))\n",
    "  \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.utils import Sequence\n",
    "import random\n",
    "\n",
    "def generatePathList(patients, test_size):\n",
    "    parent_path = 'chbfig/'\n",
    "    pathList = []\n",
    "    for indexPatient in range(0, len(patients)):\n",
    "        sub_path = 'chb'+patients[indexPatient]+'/'\n",
    "        directory_name = parent_path+sub_path\n",
    "        for filename in os.listdir(directory_name):\n",
    "            pathList.append(directory_name+filename)\n",
    "    L = len(pathList)\n",
    "    test_index = int(L*test_size)\n",
    "    index = random.sample(range(L), L)\n",
    "    return index[:test_index],index[test_index:],pathList\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, index, pathList, parent_path = 'chbfig/', batch_size=32):\n",
    "        self.batch_size = batch_size\n",
    "        self.parent_path = parent_path\n",
    "        self.pathList = pathList\n",
    "        self.index = index\n",
    "        self.L = len(self.index)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.L - self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indexs = self.index[idx:(idx+self.batch_size)]\n",
    "        image_path = [self.pathList[k] for k in batch_indexs]\n",
    "    \n",
    "        return self._load_image(image_path)\n",
    "\n",
    "  \n",
    "    def _load_image(self, image_path):\n",
    "        features = np.zeros(((len(image_path)),23,256))\n",
    "        labels = np.zeros((len(image_path)),dtype=int)\n",
    "        i = 0 #the feature index\n",
    "        for name in image_path:\n",
    "            #print(name)\n",
    "            if '_seizure_' in name:\n",
    "                features[i] = np.array(Image.open(name))[0:23,:]\n",
    "                labels[i] = 1\n",
    "            elif '_nonseizure_' in name:\n",
    "                features[i] = np.array(Image.open(name))[0:23,:]\n",
    "                labels[i] = 0\n",
    "            i = i+1\n",
    "        #print(features)\n",
    "        #print(labels)\n",
    "        #print(np.expand_dims(np.array(features), axis=3).shape)\n",
    "        #print(labels.shape)\n",
    "        return np.expand_dims(np.array(features), axis=3),labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense, Activation, Flatten, LSTM, Bidirectional, ConvLSTM2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, TimeDistributed, SimpleRNN, GRU\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (2, 4), input_shape=((23, 256, 1))))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 4)))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Conv2D(32, (2, 4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 4)))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Conv2D(32, (2, 4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 4)))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(Bidirectional(GRU(32)))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(metrics=['accuracy',keras.metrics.Recall(name='sen')], \n",
    "              loss='binary_crossentropy', optimizer=sgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'cks')\n",
    "if os.path.isdir(save_dir) is not True:\n",
    "        os.makedirs(save_dir)\n",
    "filepath = \"model_{epoch:03d}-{val_accuracy:.2f}-{val_sen:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(os.path.join(save_dir, filepath), verbose=0,\n",
    "                             save_best_only=False, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id, train_id, path_list = generatePathList(patients,test_size=0.3) # 30% test_size \n",
    "train_data = DataGenerator(train_id, path_list)\n",
    "test_data = DataGenerator(test_id, path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=train_data, epochs=50, verbose=1, callbacks=[checkpoint], steps_per_epoch=None, \n",
    "                    validation_data=test_data, class_weight={0:1, 1:50}, workers=4, use_multiprocessing=True,\n",
    "                    shuffle=False, initial_epoch=0)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
